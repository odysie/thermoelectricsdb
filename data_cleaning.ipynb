{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning, adding metadata, normalising etc.\n",
    "\n",
    "data cleaning and normalisation for the extracted thermoelectric database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from pprint import pprint\n",
    "from string import ascii_letters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_prefix = \"example_\" # prefix to be prepended to saved database name(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1580,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take in the database from it's raw csv form, following thermoelectric parsing (te_parse)\n",
    "database_path = \"example_database.csv\"\n",
    "df = pd.read_csv(database_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when working witha a database that has all five thermoelectric models,\n",
    "# and wanting to aggregate the data after cleaning (for inference or comparison),\n",
    "# then set this to True. Saves an intermediary format on which the \"data_aggregation.ipynb\" notebook runs.\n",
    "save_intermediary = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metadata\n",
    "#### (adding Publihser, Open Access, and Date tags)\n",
    "Using custom functions instead of the metadata from chemdataextractor. These rely on the filename.\n",
    "filename structure = \"article-\" + DOI with hyphens instead of backslashes + file extension (.txt or .xml or .html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "metadata": {},
   "outputs": [],
   "source": [
    "extension_to_publisher = {'xml':'Elsevier', 'html':'RSC', 'txt':'Springer'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['publisher'] = df.filename.apply(lambda x: extension_to_publisher[x.rsplit('.',1)[1]]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Open Access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'resources', 'open_access_filenames_list.json'),'r') as f:\n",
    "    oa_filenames = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add open acces (oa) tags\n",
    "df['oa'] = df.filename.apply(lambda x: \"yes\" if x in oa_filenames else \"no\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Publication Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(os.getcwd(), 'resources', 'dates_dictionary.json'),'r') as jj:\n",
    "    dates_dict = json.load(jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add year of publication (yop)\n",
    "df['yop'] = df.filename.apply(lambda x: dates_dict[x] if x in dates_dict.keys() else np.nan).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Springer titles weren't collected during extraction, so add separately\n",
    "with open(os.path.join(os.getcwd(), 'resources', 'springer_titles_dictionary.json'), 'r') as fp:\n",
    "    springer_titles = json.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_springer_titles(df):\n",
    "    if df.title == \"title_fail\":\n",
    "        return springer_titles[df.filename]\n",
    "    else:\n",
    "        return df.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1590,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.title = df.apply(add_springer_titles, axis=1).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1591,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = 'compound_name model raw_value raw_units value units temp_value temp_units room_temperature editing\\\n",
    " excerpt filename error process pressure_value pressure_units direction_of_measurement labels parser specifier title\\\n",
    " publisher yop oa'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1592,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordering and skimming\n",
    "df = df[ordered_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning \n",
    "##### (removing duplicates, entries without letters, and huge entires > 90 characters long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1593,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop duplicates\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1594,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no Unnamed: 0 column\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "except KeyError as e:\n",
    "    print(\"no Unnamed: 0 column\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1595,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_name'] = df.compound_name.apply(lambda x: x[2:-2].split(\"', '\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1596,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['first_name'] = df.clean_name.apply(lambda x: x[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trying to remove some false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1597,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify any entries without alphabetical letters\n",
    "\n",
    "def has_letters(s):\n",
    "    for c in s:\n",
    "        if c in ascii_letters:\n",
    "            return True\n",
    "    return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1598,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove entries without alphabetical letters\n",
    "df = df[df.first_name.apply(has_letters)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1599,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove huge entries\n",
    "df = df[df.first_name.apply(lambda x: False if len(x) > 79 else True)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1600,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove some problematic entries, which are due to referencing (e.g. the sample containing 6 % CaTe.\n",
    "# At some point we may be smart about that and use some coreference resolution by looking at the other\n",
    "# extracted compounds from the same article and chekcing if the dopings match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1601,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>excerpt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [first_name, excerpt]\n",
       "Index: []"
      ]
     },
     "execution_count": 1601,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number something(e.g. at wt etc.) % CEM(not spaces)\n",
    "def check_problematic_form(str):\n",
    "    if re.match(r\"^\\d+\\s.+\\s%\\s[^\\s]+$\", str):\n",
    "        return True\n",
    "    return False\n",
    "df[df.first_name.apply(check_problematic_form)][\"first_name excerpt\".split()].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1602,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number % CEM\n",
    "def check_problematic_form2(str):\n",
    "    if re.match(r\"^\\d+\\s%\\s[^\\s]+$\", str):\n",
    "        return True\n",
    "    return False\n",
    "problematic2 = df[df.first_name.apply(check_problematic_form2)][\"first_name excerpt filename\".split()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Just noting the normalised_model, without conducting any units or value normalisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1603,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NORMALISE electrical models\n",
    "# normalised_model essentially just reffers to the property\n",
    "electrical_models = 'Conductivity Conductivity2 Resistivity'\n",
    "df['normalised_model'] = df.model.apply(lambda x: 'Conductivity' if x in electrical_models else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1604,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = 'compound_name first_name normalised_model model raw_value raw_units value units temp_value room_temperature temp_units editing\\\n",
    " excerpt filename error process pressure_value pressure_units direction_of_measurement labels parser specifier title\\\n",
    " publisher yop oa'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1605,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordering and skimming\n",
    "df = df[ordered_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding pressure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1606,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pressure was added post-extraction,\n",
    "# using the Pressure class in chemdataextractor.model.units.thermoelectric_models.py,\n",
    "# and was associated to results with excerpts\n",
    "press = pd.read_pickle(\"resources/pressures_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1607,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simplify_pressure(s):\n",
    "    if s:\n",
    "        p = s[0]['Pressure']\n",
    "        return [p['value'][0], p['raw_units'].replace(\"(\",\"\").replace(\")\",\"\")]\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1608,
   "metadata": {},
   "outputs": [],
   "source": [
    "press['simple'] = press.results.apply(simplify_pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1609,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_excerpt(s):\n",
    "    if \"FROM\" in s:\n",
    "        return s.split(\"FROM: \")[0][1:-1]\n",
    "    else:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1610,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_pressure(s):\n",
    "    r = recover_excerpt(s)\n",
    "    if r in press.excerpt.unique():\n",
    "        return press[press.excerpt == r].simple.values[0]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1611,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pressure\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1612,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"pressure\"] = df.excerpt.apply(extract_pressure)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Getting real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1613,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_number_list2(x):\n",
    "    try:\n",
    "        x_list = x[1:-1].split(',')\n",
    "\n",
    "        return [float(n) for n in x_list]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temp_number_list(x):\n",
    "    if x == '-':\n",
    "        # this is not sufficient, since it doesn't account for extractions where there are both room temp\n",
    "        # and value extractions. It's just a stepping stone\n",
    "        return [295] \n",
    "    else:\n",
    "        x_list = x[1:-1].split(',')\n",
    "        return [float(n) for n in x_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1615,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_from_list(x):\n",
    "    return (sum(x) / len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1616,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['temp_numbers'] = df.temp_value.apply(make_temp_number_list)  # just a stepping stone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1617,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "count_dashed = (df.room_temperature != \"-\").sum()\n",
    "if count_dashed == 0:\n",
    "    print(\"WAIT! there seem to be no dashes in room temperature, please check that normalising will work.\")\n",
    "else:\n",
    "    print(count_dashed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1618,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp_value</th>\n",
       "      <th>temp_numbers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-</td>\n",
       "      <td>[295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-</td>\n",
       "      <td>[295]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[793.0]</td>\n",
       "      <td>[793.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[900.0]</td>\n",
       "      <td>[900.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[300.0]</td>\n",
       "      <td>[300.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  temp_value temp_numbers\n",
       "0          -        [295]\n",
       "1          -        [295]\n",
       "2    [793.0]      [793.0]\n",
       "3    [900.0]      [900.0]\n",
       "4    [300.0]      [300.0]"
      ]
     },
     "execution_count": 1618,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# temp_value is just a string, while temp numbers is a list of numbers\n",
    "df['temp_value temp_numbers'.split()].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising temperature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1619,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_temp_normalised_list(df):\n",
    "    # prioritise room temperature in the case where there is both room temp mention and numerical value!\n",
    "    if df.room_temperature != \"-\":  # make sure we haven't replaced '-' with something else\n",
    "        return [295]\n",
    "    if df.temp_units == 'Celsius^(1.0)':\n",
    "        return [t + 273 for t in df.temp_numbers]\n",
    "    elif df.temp_units == 'Fahrenheit^(1.0)':\n",
    "        return [(t - 32) * 5/9 + 273 for t in df.temp_numbers]\n",
    "\n",
    "    else:  # if Kelvin\n",
    "        return df.temp_numbers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1620,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalised_temp_values'] = df.apply(make_temp_normalised_list, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1621,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalised_temp_avg\"] = df.normalised_temp_values.apply(get_average_from_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1622,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"normalised_temp_units\"] = \"Kelvin^(1.0)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1623,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['value_numbers'] = df.value.apply(make_number_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1624,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>compound_name</th>\n",
       "      <th>value_numbers</th>\n",
       "      <th>units</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [compound_name, value_numbers, units]\n",
       "Index: []"
      ]
     },
     "execution_count": 1624,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seebeck V/C is the same as V/K (change per kelvin = chenge per celsius)\n",
    "df[df.units == '(10^-6.0) * Celsius^(-1.0)  Volt^(1.0)']['compound_name value_numbers units'.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1625,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalise_units_prefix(df):\n",
    "    exponent_list = re.findall('\\(10\\^(\\-?\\d\\d?).0\\)', df.units) #find all the powers of 10 and return the exponent\n",
    "    if exponent_list:\n",
    "        return [v * 10**int(exponent_list[0]) for v in df.value_numbers]\n",
    "    else:\n",
    "        return df.value_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1626,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalised_values'] = df.apply(normalise_units_prefix, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1627,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix the values for resistivity.\n",
    "\n",
    "def normalise_resistivity_values(df):\n",
    "    try:\n",
    "        if df.model == 'Resistivity':\n",
    "            return [1.0 / v for v in df.normalised_values]\n",
    "        else:\n",
    "            return df.normalised_values\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1628,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop some wrong zero values to avoid zero division\n",
    "# use apply to compare list entry to list\n",
    "df = df[df.normalised_values.apply(lambda x: x != [0.0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1629,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.normalised_values = df.apply(normalise_resistivity_values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1630,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalised_avg'] = df.normalised_values.apply(get_average_from_list)\n",
    "# average of inverse, for resistivity extractions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalising units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1631,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_mod_dict = {'ThermCond': 'Kelvin^(-1.0)  Meter^(-1.0)  Watt^(1.0)',\n",
    " 'ZT': '-',\n",
    " 'Conductivity': 'Meter^(-1.0)  Siemens^(1.0)',\n",
    " 'Seebeck': 'Kelvin^(-1.0)  Volt^(1.0)',\n",
    " 'PF': 'Kelvin^(-2.0)  Meter^(-1.0)  Watt^(1.0)'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1632,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['normalised_units'] = df.normalised_model.apply(lambda x: norm_mod_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1633,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace('-', np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thermal conductivity (total, lattice, electronic) and electrical conductivity (ionic and normal) tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1634,
   "metadata": {},
   "outputs": [],
   "source": [
    "def thermal_tagging(df):\n",
    "    if df.normalised_model == \"ThermCond\":\n",
    "        tag = \"total\"\n",
    "        x = df.specifier\n",
    "        \n",
    "        if ('el' in x) or ('κe' in x) or ('κ_e' in x) or ('λe' in x) or ('λ_e' in x) :\n",
    "            tag = 'electronic'\n",
    "        if ('p' in x) or ('L' in x) or ('la' in x) or ('κl' in x) or ('κ_l' in x):\n",
    "            tag = 'lattice'\n",
    "        return tag\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1635,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.insert(4, \"type\", df.apply(thermal_tagging, axis=1), True) #True is for inplace, but the paramter name ain't inplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1636,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ionic conductivity tagging\n",
    "df.loc[df.specifier.str.contains(\"[Ii]on\"), \"type\"] = \"ionic\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1637,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = 'compound_name first_name\\\n",
    " normalised_model model type\\\n",
    " normalised_temp_values normalised_temp_avg normalised_temp_units temp_value\\\n",
    " normalised_values normalised_avg normalised_units editing pressure\\\n",
    " excerpt filename error process direction_of_measurement labels parser specifier title\\\n",
    " publisher yop oa'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1638,
   "metadata": {},
   "outputs": [],
   "source": [
    "# order\n",
    "df = df[ordered_columns].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1639,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1640,
   "metadata": {},
   "outputs": [],
   "source": [
    "def temperature_gradient_problem(df):\n",
    "    if re.search(\"(temperature (difference|gradient))|Δ\", str(df.excerpt)) and (df.normalised_temp_avg < 290):\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1641,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_temp_and_process(df):\n",
    "    if isinstance(df.temp_value, str) and isinstance(df.process, str):\n",
    "        temp_val = df.temp_value[1:-1].split(\",\")[0].split(\".\")[0]\n",
    "        if temp_val in df.process:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1642,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db[~ db.apply(temperature_gradient_problem, axis=1)].copy()\n",
    "db = db[~ db.compound_name.str.contains(\"temp\", na=False)].copy()\n",
    "db = db[~ db.apply(matching_temp_and_process, axis=1)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1643,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db[~((db.normalised_temp_avg < 0) | (db.normalised_temp_avg > 2500))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1644,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_names = \"ZT ThermCond Conductivity PF Seebeck\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1645,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove negative PF values\n",
    "db = db[~((db.normalised_model == \"PF\") & (db.normalised_avg < 0))].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1646,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop too small ZT values\n",
    "db = db[~((db.normalised_model == \"ZT\") & (db.normalised_avg < 10**(-18)))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1647,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no 'Unnamed: 0' column.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    db.drop([\"Unnamed: 0\"], axis=1, inplace=True)\n",
    "except KeyError:\n",
    "    print(\"no 'Unnamed: 0' column.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1648,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if True, saves intermediary version, used for aggregation\n",
    "if save_intermediary:\n",
    "    database_name = \"intermediary_database.csv\"\n",
    "    save_name = name_prefix + database_name\n",
    "\n",
    "    if not os.path.exists(save_name):\n",
    "        db.to_csv(save_name)\n",
    "        print(f\"Saved {save_name}.\")\n",
    "    else:\n",
    "        save = input(f\"'{save_name}' already exists, would you like to overwrite? [Y/n]\")\n",
    "        if save == \"Y\":\n",
    "            db.to_csv(save_name)\n",
    "            print(f\"Overwrote {save_name}\")\n",
    "        else:\n",
    "            print(\"Skipping save.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting to main format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1649,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = \"first_name labels editing normalised_model type specifier normalised_values \\\n",
    "normalised_units normalised_temp_values normalised_temp_units normalised_avg normalised_temp_avg pressure process \\\n",
    "direction_of_measurement filename title oa publisher yop\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1650,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db[ordered_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1651,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_list = \"Name Label Editing Model Model_Type Specifier Value Units Temperature_Value Temperature_Units \\\n",
    "Value_Average Temperature_Average Pressure Process Direction_of_Measurement DOI Title Access_Type Publisher \\\n",
    "Publication_Year\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1652,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(ordered_columns) == len(renaming_list):\n",
    "    renaming_dict = {ordered_columns[i] : renaming_list[i] for i in range(len(ordered_columns))}\n",
    "else:\n",
    "    raise KeyError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1653,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename the columns according to the final (main) format\n",
    "db.rename(renaming_dict, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1654,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_access_type_entries(x):\n",
    "    return \"open\" if x == \"yes\" else \"payment\"\n",
    "\n",
    "db.Access_Type = db.Access_Type.apply(change_access_type_entries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding authors and journal from chemataextractor's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = os.path.join(os.getcwd(), 'resources', 'metadata_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta_path, \"rb\") as handle:\n",
    "    meta_dict = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1657,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_to_df(df):\n",
    "    doi = df.DOI\n",
    "    try:\n",
    "        authors = meta_dict[doi]['authors']\n",
    "    except KeyError:\n",
    "        authors = np.nan\n",
    "    try:\n",
    "        journal = meta_dict[doi][\"journal\"]\n",
    "    except KeyError:\n",
    "        journal = np.nan\n",
    "\n",
    "        \n",
    "    df.authors = authors\n",
    "    df.journal = journal\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1658,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in \"authors journal\".split():\n",
    "    db[c] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1659,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.apply(meta_to_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1660,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the DOI from the filename format\n",
    "def return_doi_to_original_form(d):\n",
    "    d = list(d.rsplit('.',1)[0]) # split and index to skip file extension, transform to list\n",
    "    d[7] = \"/\"  # replace affected hyphen with original slash\n",
    "    return \"\".join(d) # join and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1661,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.DOI = db.DOI.apply(return_doi_to_original_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1662,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rename({s: s.capitalize() for s in \"authors journal\".split()}, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving formatted main database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1663,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved example_main_database.csv\n"
     ]
    }
   ],
   "source": [
    "database_name = \"main_database.csv\"\n",
    "save_name = name_prefix + database_name\n",
    "\n",
    "if not os.path.exists(save_name):\n",
    "    db.to_csv(save_name, index=False)\n",
    "    print(f\"Saved {save_name}\")\n",
    "else:\n",
    "    save = input(f\"'{save_name}' already exists, would you like to overwrite? [Y/n]\")\n",
    "    if save == \"Y\":\n",
    "        db.to_csv(save_name, index=False)\n",
    "        print(f\"Overwrote {save_name}\")\n",
    "    else:\n",
    "        print(\"Skipping save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
