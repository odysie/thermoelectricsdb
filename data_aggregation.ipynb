{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Aggregation\n",
    "#### the data aggregation procedure described in the project, followed by the inference of values\n",
    "#### only applicable to a databse with all five properties (ZT, thermal conductivity, electrical conductivity, Seebeck coefficient, PF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from functools import reduce\n",
    "import math\n",
    "import json\n",
    "import statistics\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1152,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_prefix = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expects the 'intermediary' version of a database, obtained by processing \n",
    "# an extracted database with 5 different thermoelectric-materials properties present,\n",
    "# and setting save_intermediary = True in the \"data_cleaning.ipynb\" notebook.\n",
    "\n",
    "intermediary_database_path = \"full_intermediary_database.csv\"\n",
    "\n",
    "if os.path.exists(intermediary_database_path):\n",
    "    dd = pd.read_csv(intermediary_database_path)\n",
    "else:\n",
    "    print(\"Expects an intermediary database, from data cleaning.\")\n",
    "    raise FileNotFoundError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1154,
   "metadata": {},
   "outputs": [],
   "source": [
    "if dd.normalised_model.nunique() != 5:\n",
    "    print(\"Expected 5 different property models.\")\n",
    "    raise Exception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregating between thermal conductivity types first (total, electronic, and lattice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1155,
   "metadata": {},
   "outputs": [],
   "source": [
    "therm = dd[dd.normalised_model == \"ThermCond\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot = therm[therm.type == 'total'].copy()\n",
    "ele = therm[therm.type == 'electronic'].copy()\n",
    "lat = therm[therm.type == 'lattice'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1157,
   "metadata": {},
   "outputs": [],
   "source": [
    "ele.rename({'normalised_avg' : 'EleThermCond_value'}, axis=1, inplace = True)\n",
    "ele.drop(columns=['normalised_model','type', 'specifier'], inplace = True)\n",
    "lat.rename({'normalised_avg' : 'LatThermCond_value'}, axis=1, inplace = True)\n",
    "lat.drop(columns=['normalised_model','type'], inplace = True)\n",
    "tot.rename({'normalised_avg' : 'ThermCond_value'}, axis=1, inplace = True)\n",
    "tot.drop(columns=['normalised_model','type'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use inner merging to get only the entries which have both an electronic and lattice component\n",
    "ele_lat = pd.merge(ele, lat, on=['first_name','normalised_temp_avg','filename',\n",
    "                                'parser', 'oa', 'publisher', 'editing', 'pressure', 'error', 'process',\n",
    "                                'labels', 'direction_of_measurement'], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ele_and_lat(df):\n",
    "    return (df.EleThermCond_value + df.LatThermCond_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1160,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ele_lat.empty:\n",
    "    ele_lat['SUMThermCond_value'] = ele_lat.apply(add_ele_and_lat, axis=1)\n",
    "else:\n",
    "    ele_lat['SUMThermCond_value'] = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1161,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_th = therm[therm.type == 'total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1162,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_th = tot_th.drop(['type','specifier'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1163,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['first_name',\n",
    "       'normalised_avg', 'normalised_temp_values', 'parser', 'filename', 'oa', 'yop', 'publisher',\n",
    "       'editing', 'pressure', 'error', 'process', 'labels', 'direction_of_measurement']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Making changes to include electronic (k_e) and lattice (k_p) as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1164,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_th = therm[therm.type == 'total'][cols].rename({\"normalised_avg\":\"k\"}, axis=1).copy()\n",
    "e_th = therm[therm.type == 'electronic'][cols].rename({\"normalised_avg\":\"k_e\"}, axis=1).copy()\n",
    "p_th = therm[therm.type == 'lattice'][cols].rename({\"normalised_avg\":\"k_p\"}, axis=1).copy()\n",
    "zt = dd[dd.normalised_model == 'ZT'][cols].rename({\"normalised_avg\":\"ZT\"}, axis=1).copy()\n",
    "pf = dd[dd.normalised_model == 'PF'][cols].rename({\"normalised_avg\":\"PF\"}, axis=1).copy()\n",
    "s = dd[dd.normalised_model == 'Seebeck'][cols].rename({\"normalised_avg\":\"S\"}, axis=1).copy()\n",
    "el = dd[dd.normalised_model == 'Conductivity'][cols].rename({\"normalised_avg\":\"s\"}, axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1165,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [tot_th, e_th, p_th, pf, s, el, zt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1166,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_columns = [\n",
    " 'first_name',\n",
    " 'normalised_temp_values',\n",
    " 'filename',\n",
    " 'oa', 'yop',\n",
    " 'parser',\n",
    " 'publisher',\n",
    " 'editing', 'pressure', 'process', 'labels', 'direction_of_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect(s):\n",
    "    \"\"\"used to collect multiple values for same merged columns\"\"\"\n",
    "    l = []\n",
    "    for x in s:\n",
    "        if has(x):\n",
    "            l.append(x)\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1168,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_copy = dfs.copy()\n",
    "dfs_collect = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for brevity. Return False for both [] and np.nan. Unfortunately bool(np.nan) evaluates to True\n",
    "def has(x):\n",
    "    if x == []:\n",
    "        return False\n",
    "    return not (x is np.nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_mods = \"k k_e k_p ZT PF S s\".split()\n",
    "\n",
    "# collect mutliple values for same merge columns (e.g. same compound, same temp, diff value averages)\n",
    "for dfc in dfs_copy:\n",
    "    df_mod = [m for m in dfs_mods if m in dfc.columns][0]\n",
    "    dfs_collect.append(dfc.groupby(merge_columns, dropna = False)[df_mod].apply(collect).reset_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges the databases in pairs, on common compound, labels, filename, and temperature values\n",
    "# if a value does not exist, it is populated by NaN\n",
    "db = reduce(lambda df_left,df_right: pd.merge(df_left, df_right, how='outer',\n",
    "                                              on=merge_columns), dfs_collect)\n",
    "\n",
    "# NB If there were multiple values, then they are chosen indiscriminantly, addressed this via dfs_collect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_columns = ['k', 'k_e', 'k_p', 'PF', 'S', 's', 'ZT']\n",
    "def count_nans(df):\n",
    "    \"\"\"get the total number of nans for the columsn we care about\"\"\"\n",
    "    return df[model_columns].isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20819\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20819"
      ]
     },
     "execution_count": 1173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = 0\n",
    "for dfc in dfs_collect:\n",
    "    length += len(dfc)\n",
    "print(length)\n",
    "\n",
    "# sanity check two numbers must agree (the rows before aggregate, and the non nan entries in the aggregate db)\n",
    "db[model_columns].size - count_nans(db)\n",
    "# db[model_columns].notna().sum().sum()  # otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_quantities(df):\n",
    "    \"\"\"count how many of the 5 thermoelectric properties are found in each row\"\"\"\n",
    "    c=0\n",
    "    if has(df.ZT):\n",
    "        c+=1\n",
    "    if has(df.S):\n",
    "        c+=1\n",
    "    if has(df.s):\n",
    "        c+=1\n",
    "    if has(df.k):  # ignoring k_e and k_p\n",
    "        c+=1\n",
    "    if has(df.PF):\n",
    "        c+=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {},
   "outputs": [],
   "source": [
    "db['counts'] = db[\"ZT S s k PF\".split()].apply(count_quantities, axis=1)\n",
    "# NB count is a just column that was added, value_counts is a standard pandas function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# square Seebeck coefficient\n",
    "db.S = db.S.apply(lambda l: [x**2.0 for x in l] if (l is not np.nan) else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename Seebeck column\n",
    "db = db.rename({'S': 'S_2'},axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db[['first_name', 'normalised_temp_values',\n",
    "    'ZT', 'PF', 'S_2', 's', 'k', 'k_e', 'k_p',\n",
    "    'counts','parser', 'filename', 'publisher', 'oa', 'yop',\n",
    "    'editing', 'pressure', 'process', 'labels', 'direction_of_measurement']].copy()  # set order. Maybe should sort as well?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_number_list2(x):\n",
    "    try:\n",
    "        x_list = x[1:-1].split(',')\n",
    "\n",
    "        return [float(n) for n in x_list]\n",
    "    except:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1180,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.normalised_temp_values = db.normalised_temp_values.apply(make_number_list2).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keep single values for comparison and inference. (avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Although not necessary, having a unique value for each property at each data record, facilitates inference\n",
    "# and comparison between the aggregated data. There are several options, such as taking the average, mode, median\n",
    "# or other options, when there are multiple values present. This procedure takes the average of values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1182,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get averages of values (which are already averages) to perform comparison. It's simple and somewhat reasonable\n",
    "\n",
    "# to clarify: some extractions return a range, which has been averaged\n",
    "# then we got those averages, and where the merged columns agreed, added them into single records, in a list\n",
    "# i.e. we collected different extractions with diff average values, for the same things, and added them into a list\n",
    "# and now we get the average of the values in that list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1183,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_names = \"ZT PF k S_2 s k_e k_p\".split() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1184,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in mod_names + [\"normalised_temp_values\"]:\n",
    "    db[m] = db[m].apply(lambda l: statistics.mean(l) if isinstance(l, list) else np.nan)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1185,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code merges the 5 normalised databases (on common compound, doi, and temperature) and then uses\n",
    "# the interdependency between the quantities, to infer new values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1186,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bcreate new column to hold the steps of the inference and comparison procedure\n",
    "db['inference'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1187,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for brevity. A bit more flexible than notna because it doesn't crash for conversions (?)\n",
    "def has(x):\n",
    "    return not math.isnan(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inference (updates original column) if unpopulated\n",
    "\n",
    "def get_PF_from_2(df):\n",
    "    # ZT and k calculation\n",
    "    if has(df.ZT) and has(df.k):\n",
    "        calc1 = df.ZT * df.k / df.normalised_temp_values\n",
    "        if not(has(df.PF)):\n",
    "            df.PF = calc1\n",
    "            df.inference += '[ZT/kT -> PF]'\n",
    "            \n",
    "    # S^2 and s calculation\n",
    "    elif has(df.S_2) and has(df.s):\n",
    "        calc2 = df.S_2 * df.s\n",
    "        if not has(df.PF):\n",
    "            df.PF = calc2\n",
    "            df.inference += '[S^2*s -> PF]'\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1189,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.apply(get_PF_from_2, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1190,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat similar procedure for the rest of the quantities\n",
    "def get_S2(df):\n",
    "    # PF and s\n",
    "    if has(df.PF) and has(df.s):\n",
    "        calc1 = df.PF / df.s\n",
    "        if not(has(df.S_2)):\n",
    "            df.S_2 = calc1\n",
    "            df.inference += '[PF/s -> S^2]'\n",
    "    return df\n",
    "    # S^2 = ZT * k / (s * T) is skipped because that would have given a PF in first step via PF = ZT * k / T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1191,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.apply(get_S2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1192,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_s(df):    \n",
    "    # PF and S^2\n",
    "    if has(df.PF) and has(df.S_2):\n",
    "        calc1 = df.PF / df.S_2\n",
    "        if not(has(df.s)):\n",
    "            df.s = calc1\n",
    "            df.inference += '[PF/S^2 -> s]'\n",
    "    return df\n",
    "    # s = ZT * k / (s^2 * T) is skipped because that would have given a PF in first step via PF = ZT * k / T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1193,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.apply(get_s, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1194,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ZT(df):\n",
    "    # PF and k\n",
    "    if has(df.PF) and has(df.k):\n",
    "        calc1 = df.PF * df.normalised_temp_values / df.k\n",
    "        if not(has(df.ZT)):\n",
    "            df.ZT = calc1\n",
    "            df.inference += '[PF*T/k -> ZT]'\n",
    "    return df\n",
    "    # ZT = S^2 * s * T / k is skipped because that would have given a PF in first step via PF = S^2 * s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1195,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.apply(get_ZT, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1196,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k(df):\n",
    "    # PF and ZT\n",
    "    if has(df.PF) and has(df.ZT):\n",
    "        calc1 = df.PF * df.normalised_temp_values / df.ZT\n",
    "        if not(has(df.k)):\n",
    "            df.k = calc1\n",
    "            df.inference += '[PF*T/ZT -> k]'\n",
    "    return df\n",
    "    # k = S^2 * s * T / ZT is skipped because that would have given a PF in first step via PF = S^2 * s "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1197,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.apply(get_k, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are the final logistics of inference\n",
    "results = db.inference.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1199,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_names = \"ZT s S_2 PF k\".split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1200,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rename({\"counts\": \"original_counts\"}, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_aggregated_quantities(df):\n",
    "    \"\"\"same as counta_quantities, but with S_2 for Seebeck coefficient squared\"\"\"\n",
    "    c=0\n",
    "    if has(df.ZT):\n",
    "        c+=1\n",
    "    if has(df.S_2):\n",
    "        c+=1\n",
    "    if has(df.s):\n",
    "        c+=1\n",
    "    if has(df.k):\n",
    "        c+=1\n",
    "    if has(df.PF):\n",
    "        c+=1\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1202,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.insert(db.columns.get_loc(\"original_counts\") + 1, \"new_counts\", db.apply(count_aggregated_quantities, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### formatting aggregate database with inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1203,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ordered_columns = ['first_name',\n",
    " 'normalised_temp_values',\n",
    " 'ZT',\n",
    " 'PF',\n",
    " 'S_2',\n",
    " 's',\n",
    " 'k',\n",
    " 'k_e',\n",
    " 'k_p',\n",
    " 'original_counts',\n",
    " 'new_counts',\n",
    " 'filename',\n",
    " 'publisher',\n",
    " 'oa',\n",
    " 'yop',\n",
    " 'editing',\n",
    " 'pressure',\n",
    " 'process',\n",
    " 'labels',\n",
    " 'direction_of_measurement',\n",
    " 'inference']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1204,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db[db_ordered_columns].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1205,
   "metadata": {},
   "outputs": [],
   "source": [
    "renaming_dict = {\n",
    " 'first_name': 'Name',\n",
    " 'labels': 'Label',\n",
    " 'editing': 'Editing',\n",
    " 'normalised_model': 'Model',\n",
    " 'type': 'Model_Type',\n",
    " 'specifier': 'Specifier',\n",
    " 'normalised_values': 'Value',\n",
    " 'normalised_units': 'Units',\n",
    " 'normalised_temp_values': 'Temperature_Value',\n",
    " 'normalised_temp_units': 'Temperature_Units',\n",
    " 'normalised_avg': 'Value_Average',\n",
    " 'normalised_temp_avg': 'Temperature_Average',\n",
    " 'pressure': 'Pressure',\n",
    " 'process': 'Process',\n",
    " 'direction_of_measurement': 'Direction_of_Measurement',\n",
    " 'filename': 'DOI',\n",
    " 'title': 'Title',\n",
    " 'oa': 'Access_Type',\n",
    " 'publisher': 'Publisher',\n",
    " 'yop': 'Publication_Year',\n",
    " 'S_2': 'S^2',\n",
    " 'original_counts': 'Original_Counts',\n",
    " 'new_counts': 'New_Counts',\n",
    " 'inference': 'Inference'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Temperature_Value</th>\n",
       "      <th>ZT</th>\n",
       "      <th>PF</th>\n",
       "      <th>S^2</th>\n",
       "      <th>s</th>\n",
       "      <th>k</th>\n",
       "      <th>k_e</th>\n",
       "      <th>k_p</th>\n",
       "      <th>Original_Counts</th>\n",
       "      <th>...</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Access_Type</th>\n",
       "      <th>Publication_Year</th>\n",
       "      <th>Editing</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Process</th>\n",
       "      <th>Label</th>\n",
       "      <th>Direction_of_Measurement</th>\n",
       "      <th>Inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>% SnS : Bi2Te3 nanocomposite</td>\n",
       "      <td>295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1016-j.jallcom.2020.156233.xml</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Bi,Sb)2-xSnxSe3–4xCl4x</td>\n",
       "      <td>773.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1016-j.mssp.2019.01.021.xml</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Ce0.2Zr0.2Hf0.2Sn0.2Ti0.2)O2</td>\n",
       "      <td>295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1039-c9ta05698j.html</td>\n",
       "      <td>RSC</td>\n",
       "      <td>no</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  Temperature_Value    ZT      PF  S^2   s  \\\n",
       "0   % SnS : Bi2Te3 nanocomposite              295.0   NaN     NaN  NaN NaN   \n",
       "1        (Bi,Sb)2-xSnxSe3–4xCl4x              773.0  0.61  0.0004  NaN NaN   \n",
       "2  (Ce0.2Zr0.2Hf0.2Sn0.2Ti0.2)O2              295.0   NaN     NaN  NaN NaN   \n",
       "\n",
       "       k  k_e  k_p  Original_Counts  ...                                DOI  \\\n",
       "0  0.680  NaN  NaN                1  ...  10.1016-j.jallcom.2020.156233.xml   \n",
       "1  0.475  NaN  NaN                3  ...     10.1016-j.mssp.2019.01.021.xml   \n",
       "2  1.280  NaN  NaN                1  ...            10.1039-c9ta05698j.html   \n",
       "\n",
       "  Publisher Access_Type Publication_Year  Editing Pressure Process Label  \\\n",
       "0  Elsevier          no              NaN      NaN      NaN     NaN   NaN   \n",
       "1  Elsevier          no              NaN      NaN      NaN     NaN   NaN   \n",
       "2       RSC          no              NaN      NaN      NaN     NaN   NaN   \n",
       "\n",
       "  Direction_of_Measurement Inference  \n",
       "0                      NaN            \n",
       "1                      NaN            \n",
       "2                      NaN            \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.rename(renaming_dict, axis=1, inplace=True)\n",
    "db.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_access_type_entries(x):\n",
    "    return \"open\" if x == \"yes\" else \"payment\"\n",
    "\n",
    "db.Access_Type = db.Access_Type.apply(change_access_type_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1208,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.Access_Type = db.Access_Type.apply(change_access_type_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Temperature_Value</th>\n",
       "      <th>ZT</th>\n",
       "      <th>PF</th>\n",
       "      <th>S^2</th>\n",
       "      <th>s</th>\n",
       "      <th>k</th>\n",
       "      <th>k_e</th>\n",
       "      <th>k_p</th>\n",
       "      <th>Original_Counts</th>\n",
       "      <th>...</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Access_Type</th>\n",
       "      <th>Publication_Year</th>\n",
       "      <th>Editing</th>\n",
       "      <th>Pressure</th>\n",
       "      <th>Process</th>\n",
       "      <th>Label</th>\n",
       "      <th>Direction_of_Measurement</th>\n",
       "      <th>Inference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>% SnS : Bi2Te3 nanocomposite</td>\n",
       "      <td>295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.680</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1016-j.jallcom.2020.156233.xml</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>payment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(Bi,Sb)2-xSnxSe3–4xCl4x</td>\n",
       "      <td>773.0</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1016-j.mssp.2019.01.021.xml</td>\n",
       "      <td>Elsevier</td>\n",
       "      <td>payment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(Ce0.2Zr0.2Hf0.2Sn0.2Ti0.2)O2</td>\n",
       "      <td>295.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>10.1039-c9ta05698j.html</td>\n",
       "      <td>RSC</td>\n",
       "      <td>payment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Name  Temperature_Value    ZT      PF  S^2   s  \\\n",
       "0   % SnS : Bi2Te3 nanocomposite              295.0   NaN     NaN  NaN NaN   \n",
       "1        (Bi,Sb)2-xSnxSe3–4xCl4x              773.0  0.61  0.0004  NaN NaN   \n",
       "2  (Ce0.2Zr0.2Hf0.2Sn0.2Ti0.2)O2              295.0   NaN     NaN  NaN NaN   \n",
       "\n",
       "       k  k_e  k_p  Original_Counts  ...                                DOI  \\\n",
       "0  0.680  NaN  NaN                1  ...  10.1016-j.jallcom.2020.156233.xml   \n",
       "1  0.475  NaN  NaN                3  ...     10.1016-j.mssp.2019.01.021.xml   \n",
       "2  1.280  NaN  NaN                1  ...            10.1039-c9ta05698j.html   \n",
       "\n",
       "  Publisher Access_Type Publication_Year  Editing Pressure Process Label  \\\n",
       "0  Elsevier     payment              NaN      NaN      NaN     NaN   NaN   \n",
       "1  Elsevier     payment              NaN      NaN      NaN     NaN   NaN   \n",
       "2       RSC     payment              NaN      NaN      NaN     NaN   NaN   \n",
       "\n",
       "  Direction_of_Measurement Inference  \n",
       "0                      NaN            \n",
       "1                      NaN            \n",
       "2                      NaN            \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 1209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Adding authors and journal from chemataextractor's metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_path = os.path.join(os.getcwd(), 'resources', 'metadata_dict.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(meta_path, \"rb\") as handle:\n",
    "    meta_dict = json.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'db' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-21ad0c09a808>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'db' is not defined"
     ]
    }
   ],
   "source": [
    "db.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1213,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meta_to_df(df):\n",
    "    doi = df.DOI\n",
    "    try:\n",
    "        authors = meta_dict[doi]['authors']\n",
    "    except KeyError:\n",
    "        authors = np.nan\n",
    "    try:\n",
    "        journal = meta_dict[doi][\"journal\"]\n",
    "    except KeyError:\n",
    "        journal = np.nan\n",
    "\n",
    "        \n",
    "    df.authors = authors\n",
    "    df.journal = journal\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1214,
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in \"authors journal\".split():\n",
    "    db[c] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1215,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db.apply(meta_to_df, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restore the DOI from the filename format\n",
    "def return_doi_to_original_form(d):\n",
    "    d = list(d.rsplit('.',1)[0]) # split and index to skip file extension, transform to list\n",
    "    d[7] = \"/\"  # replace affected hyphen with original slash\n",
    "    return \"\".join(d) # join and return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1217,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.DOI = db.DOI.apply(return_doi_to_original_form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1218,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.rename({s: s.capitalize() for s in \"authors journal\".split()}, axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1219,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_final_order = [\n",
    "    'Name',\n",
    "    'Temperature_Value',\n",
    "    'ZT', 'PF', 'S^2', 's', 'k',\n",
    "    'Original_Counts', 'New_Counts', 'Inference',\n",
    "    'Editing', 'Pressure', 'Process', 'Label', 'Direction_of_Measurement',\n",
    "    'DOI', 'Publisher', 'Access_Type', 'Publication_Year', 'Authors', 'Journal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['k_e', 'k_p']\n"
     ]
    }
   ],
   "source": [
    "print([i for i in db_final_order if i not in db.columns])\n",
    "print([c for c in db.columns if c not in db_final_order])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1221,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = db[db_final_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'aggregated_database.csv' already exists, would you like to overwrite? [Y/n]Y\n",
      "Overwrote aggregated_database.csv\n"
     ]
    }
   ],
   "source": [
    "database_name = \"aggregated_database.csv\"\n",
    "save_name = name_prefix + database_name\n",
    "\n",
    "if not os.path.exists(save_name):\n",
    "    db.to_csv(save_name, index=False)\n",
    "    print(f\"Saved {save_name}\")\n",
    "else:\n",
    "    save = input(f\"'{save_name}' already exists, would you like to overwrite? [Y/n]\")\n",
    "    if save == \"Y\":\n",
    "        db.to_csv(save_name, index=False)\n",
    "        print(f\"Overwrote {save_name}\")\n",
    "    else:\n",
    "        print(\"Skipping save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
